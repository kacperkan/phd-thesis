% --- repeat the title (AT: haven't found a more elegant way to do this...)
{
\vspace{2.0em}
\centering
\Large
\textbf{CoNeRF: Controllable Neural Radiance Fields} \\
\vspace{0.5em}
 Supplementary Material \\ \vspace{1.0em} }

 \section{Potential social impact} Our work is originally intended for
 creative and entertainment purposes, for example to allow users to easily
 edit their personal photos to have all the members of a group photo to have
 their eyes open.
  % < twocolumn
  However, as with all work that enable editable models, our method has the
  potential to be misused for malicious purposes such as deep fakes.
  We strongly advise against such misuse.
  Recent work~\cite{asnani2021reverse} has shown that it is possible to detect
  deep fakes, hinting that it should be possible to detect these deep
  learning-generated images.
  One of our future research direction is also along these lines, where we now
  aim to reliably detect images generated by our method.

\section{Architecture details}
  We present architecture of: canonicalizer $\Canonicalizer$ in
  \cref{fig:conerf-warping-field}, attribute map $\AttributeNet$ in
  \cref{fig:conerf-attribute-net}, hypermap $\hypermap$ in
  \cref{fig:conerf-hypermap}, per-attribute hypermap in
  \cref{fig:conerf-hypermap-alpha}, mask prediction network in
  \cref{fig:conerf-masknet} and the rendering network in
  \cref{fig:conerf-nerf}.
  Each network contains only fully connected layers.
  Hidden layers use ReLU activation function.
  Colors of figures correspond to colors of blocks in
  \cref{fig:conerf-laced-implicit}.

\section{Failure Cases}
  \input{fig/\conerfdirname/failure-cases}
  We identify two modes of failure cases in our approach and present them in
  \cref{fig:conerf-failure-cases}.
  In some cases with particular mask annotations, our model can struggle with
  controlling elements that occupy small space in the image.
  The problem is especially visible for controlling pendulum movement or
  opening and closing eyes.
  In the former, pendulum disappears and reappears in different places.
  In the latter, the control of eyes is periodic and there are two distant
  values in $[-1, 1]$ that produce opening eyes.
  While with careful annotations we noticed that the problem is mostly
  preventable, this problem may occur in practice.

  \begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{fig/\conerfdirname/assets/supplementary/warping-field_cropped.pdf}
    \caption{The canonicalization network takes positionally encoded raw coordinates $\bx$ and learnable per-image latent code $\bbeta$ and outputs rotation $\mathbf{r}$ expressed as a quaternion and translation $\mathbf{t}$.
      We rigidly transform each point $\bx$ with an affine transform using
      both output.
      We use windowed positional encoding \cite{park2020deformable} for $\bx$
      with 8 components, linearly increasing contribution of components
      throughout 80k steps.
      We initialize the last layer to small values so the network can learn a
      base structure of the data.
    }
    \label{fig:conerf-warping-field}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.7\linewidth]{fig/\conerfdirname/assets/supplementary/attribute-net_cropped.pdf}
    \caption{The attribute map $\AttributeNet$ takes a per-image learnable latent code $\bbeta$ and outputs $A$ attributes $\attributes$.}
    \label{fig:conerf-attribute-net}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{fig/\conerfdirname/assets/supplementary/hypermap_cropped.pdf}
    \caption{The network predicting lifted latent code $\bbeta$, takes per-image $\bbeta$ as an input, positionally encoded raw points $\bbeta$ and outputs a lifted code of size $d$.
      We use only one sine component to encode $\bx$.
    }
    \label{fig:conerf-hypermap}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=\linewidth]{fig/\conerfdirname/assets/supplementary/hypermap-alpha_cropped.pdf}
    \caption{Per-attributes hypermaps take an attribute together with encoded $\bx$ coordinates and output lifted $\attribute_a(\bx)$ ambient code of size $d$.
      We encode $\bx$ with only single component.
    }
    \label{fig:conerf-hypermap-alpha}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.5\linewidth]{fig/\conerfdirname/assets/supplementary/masknet_cropped.pdf}
    \caption{Masking network $\MaskNet$ take lifted attributes $\attributes(\bx)$, lifted latent code $\bbeta(\bx)$ and canonicalized points $\Canonicalizer(\bx)$.
      We transform $\attributes(\bx)$ and $\bbeta(\bx)$ through a windowed
      positional encoding where we start at 1k-th step linearly increasing a
      single sine component for the next 10k steps.
      Points $\Canonicalizer(\bx)$ are encoded with 8 components.
      The output is activated with a sigmoid function.
      We realize $\mathbf{m}_0(\bx)$ as $\mathbf{m}(\bx)_0 = 1 - \sum_{a \in
      A} \mathbf{m}_a(\bx)$, and clip the output to ensure the values range to
      be in $[0,1]$.
      Note that while the network shares similarities with the radiance field
      prediction part $\Representation$, it is not conditioned on view
      directions and appearance codes.
    }
    \label{fig:conerf-masknet}
  \end{figure}

  \begin{figure}
    \centering
    \includegraphics[width=0.8\linewidth]{fig/\conerfdirname/assets/supplementary/nerf_cropped.pdf}
    \caption{The radiance field prediction network predicts RGB colors $\mathbf{c}(\bx)$ and density values $\sigma(\bx)$ from canonicalized points.
      We encode points $\bx$ with 8 sine components and linearly increase
      contribution of a single component in $\attributes(\bx)$ and
      $\bbeta(\bx)$ from 1k to 11k step.
      Per-point predicted predicted attributes $\attributes(\bx)$ and lifted
      latent code $\bbeta(\bx)$ are masked by a mask predicted from the
      masking network depicted in \cref{fig:conerf-masknet}.
      The final linear layer takes additional per-image learnable appearance
      code $\psi$ to account for any visual variations that cannot be
      explained by the rest of the framework (\eg changes in lighting).
      The code can discarded during evaluation.
      The same layer is additionally conditioned on the positionally encoded
      view directions.
      We activate the color output with a sigmoid function.
    }
    \label{fig:conerf-nerf}
  \end{figure}

